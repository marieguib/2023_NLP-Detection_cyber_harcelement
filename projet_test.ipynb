{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Classification des avis sur des vêtements de femmes vendus dans le e-commerce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Est ce que les avis que l'on a des vêtements sont représentatifs de la note qui est attribuée ?\n",
    "\n",
    "Idées :\n",
    "- visualisation de données : quels types de vêtements ont les notes les plus élevées ?\n",
    "- nb d'avis donné selon l'âge des clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import string\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Import des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans un premier temps, nous allons importer nos données. Notre base de données contient des informations sur des avis de vêtements femmes vendus sur internet. Ces données sont issus d'un processus de webscrapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Clothing ID  Age                    Title  \\\n",
       "0   0          767   33                      NaN   \n",
       "1   1         1080   34                      NaN   \n",
       "2   2         1077   60  Some major design flaws   \n",
       "3   3         1049   50         My favorite buy!   \n",
       "4   4          847   47         Flattering shirt   \n",
       "\n",
       "                                         Review Text  Rating  Recommended IND  \\\n",
       "0  Absolutely wonderful - silky and sexy and comf...       4                1   \n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5                1   \n",
       "2  I had such high hopes for this dress and reall...       3                0   \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       5                1   \n",
       "4  This shirt is very flattering to all due to th...       5                1   \n",
       "\n",
       "   Positive Feedback Count   Division Name Department Name Class Name  \n",
       "0                        0       Initmates        Intimate  Intimates  \n",
       "1                        4         General         Dresses    Dresses  \n",
       "2                        0         General         Dresses    Dresses  \n",
       "3                        0  General Petite         Bottoms      Pants  \n",
       "4                        6         General            Tops    Blouses  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import des données\n",
    "data = pd.read_csv(\"Womens Clothing E-Commerce Reviews.csv\", sep = \",\")\n",
    "\n",
    "# Renomage première colonne pour pouvoir l'utiliser comme id par la suite\n",
    "data = data.rename(columns = {\"Unnamed: 0\" : \"id\"})\n",
    "\n",
    "# Affichage des 5 premières lignes\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23486, 11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre jeu de données contient 23 486 avis et 11 colonnes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Pré-traitement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour avoir des données plus propres, nous allons effectuer divers pré-traitements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \n",
    "    text = text.str.lower() # mise en minuscules du texte\n",
    "    \n",
    "    punct = string.punctuation\n",
    "    text = ''.join([char for char in text if char not in punct]) # suppression de la ponctuation\n",
    "\n",
    "    tokenizer = RegexpTokenizer('\\w+')\n",
    "    tokens = tokenizer.tokenize(text) # tokennisation du texte\n",
    "    \n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    # augmentation du nombre de caractères\n",
    "    nlp.max_length = 6807745\n",
    "    lemmatized_tokens = [token.lemma_ for token in nlp(' '.join(tokens))] # lemmatisation des tokens\n",
    "    \n",
    "    stemmer = SnowballStemmer('english')\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in lemmatized_tokens] # racinisation des tokens\n",
    "    \n",
    "    processed_text = ' '.join(stemmed_tokens) # reconstitution du texte\n",
    "    \n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On convertit notre colonne 'Review Text' en chaîne de caractères pour pouvoir utiliser toutes les fonctions de pré-traitements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Review Text'] = data['Review Text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application de la fonction preprocess_text à la colonne 'Review Text' pour avoir des avis nettoyés\n",
    "data['Review Text'] = preprocess_text(data['Review Text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On affiche notre dataframe pour vérifier que le pré-traitement soit bien réalisé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitement et séparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette partie, nous allons chercher à classifier les avis en fonction de leur note. \n",
    "\n",
    "Nous allons utiliser la colonne \"Rating\" comme étiquettes et \"Review Text\" comme valeurs. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sélection des informations dans notre dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons sélectionner les trois colonnes qui vont nous servir pour la classification dans un objectif d'optimiser les temps de calculs et de ne pas avoir d'informations superflus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>I love tracy reese dresses, but this one is no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>I aded this in my basket at hte last mintue to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Rating                                        Review Text\n",
       "2   2       3  I had such high hopes for this dress and reall...\n",
       "3   3       5  I love, love, love this jumpsuit. it's fun, fl...\n",
       "4   4       5  This shirt is very flattering to all due to th...\n",
       "5   5       2  I love tracy reese dresses, but this one is no...\n",
       "6   6       5  I aded this in my basket at hte last mintue to..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On récupère la colonne id, Rating et Review Text\n",
    "new_data = data[[\"id\", \"Rating\", \"Review Text\"]]\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suppression des valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = new_data.dropna() # On supprime les lignes avec des valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape, new_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suite à cette manipulation, nous avons "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse de la colonne \"Rating\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rating\n",
       "5    10858\n",
       "4     4289\n",
       "3     2464\n",
       "2     1360\n",
       "1      691\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyse de la colonne \"Rating\"\n",
    "data[\"Rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons ici des notes allant de 1 à 5. Nous allons diviser ces valeurs en 3 catégories : \n",
    "- -1 pour les notes allant de 1 à 2\n",
    "- 0 pour les notes égales à 3 \n",
    "- 1 pour les plus élevées (4 et 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse de la colonne \"Review Text\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre colonne correspondant aux valeurs est \"Review Text\". \\\n",
    "Cette colonne contient tous les avis laissés par les internautes sur les différents vêtements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changement des étiquettes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour réaliser notre classification, nous allons donc modifier les étiquettes comme précisé ci-dessus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_label_to_numeric(label):\n",
    "    return 1 if label == 5 else 0 if label == 3 or label == 4 else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(data):\n",
    "    labels = data[[\"id\",\"Rating\"]]\n",
    "    labels['Rating'] = labels['Rating'].apply(map_label_to_numeric)\n",
    "    labels.set_index('id', inplace=True)\n",
    "    \n",
    "    # ajouter les labels dans data selon l'id\n",
    "    data['score_avis'] = labels\n",
    "\n",
    "    # data['score_avis'] = labels\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19012\\29256686.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labels['Rating'] = labels['Rating'].apply(map_label_to_numeric)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>score_avis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>I love tracy reese dresses, but this one is no...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>I aded this in my basket at hte last mintue to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Rating                                        Review Text  score_avis\n",
       "2   2       3  I had such high hopes for this dress and reall...           0\n",
       "3   3       5  I love, love, love this jumpsuit. it's fun, fl...           1\n",
       "4   4       5  This shirt is very flattering to all due to th...           1\n",
       "5   5       2  I love tracy reese dresses, but this one is no...          -1\n",
       "6   6       5  I aded this in my basket at hte last mintue to...           1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_labels(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score_avis\n",
       " 1    10858\n",
       " 0     6753\n",
       "-1     2051\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On analyse la nouvelle colonne \"score_avis\"\n",
    "data[\"score_avis\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grâce à cette manipulation, nous pouvons observer que les avis ayant la note de 5 sont majoritaires dans notre jeu de données puisque cela correspond à la note de 1. Les avis compris entre 1 et 2 ont une proportion plus faible (-1). \n",
    "\n",
    "A présent, nous n'avons plus besoin de la colonne Rating, nous pouvons donc la supprimer du dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>score_avis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>I love tracy reese dresses, but this one is no...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>I aded this in my basket at hte last mintue to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                        Review Text  score_avis\n",
       "2   2  I had such high hopes for this dress and reall...           0\n",
       "3   3  I love, love, love this jumpsuit. it's fun, fl...           1\n",
       "4   4  This shirt is very flattering to all due to th...           1\n",
       "5   5  I love tracy reese dresses, but this one is no...          -1\n",
       "6   6  I aded this in my basket at hte last mintue to...           1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[[\"id\", \"Review Text\", \"score_avis\"]]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Division de notre dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour réaliser notre classification, nous avons besoin de séparer notre jeu de données en un jeu d'apprentissage, de validation et de test.\n",
    "\n",
    "Note :\n",
    "Les données en apprentissage automatique sont généralement séparées en trois jeux :\n",
    "+ **entraînement** : données destinées à l'apprentissage du modèle ;\n",
    "+ **validation** : données destinées à une évaluation intermédiaire du modèle pour permettre l'ajustement de ses hyperparamètres. Une fois les hyperparamètres du modèle arrêtés, on peut le ré-entraîner sur l'ensemble des données (entraînement + validation) avant de le tester sur le jeu de test ;\n",
    "+ **test** : données destinées EXCLUSIVEMENT à l'évaluation FINALE (à réaliser une fois uniquement !) du modèle choisi finalement. Elles ne doivent sous aucune forme servir à la conception du modèle. Il est donc interdit aussi bien de les examiner que d'évaluer le modèle en cours de développement sur ce jeu de données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour créer l'ensemble de validation, nous allons effectuer la manipulation à la fin du pré-traitement réalisé lors de la classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour diviser de notre jeu de données en 2 : train et test\n",
    "def split_data(data, train_ratio):\n",
    "    data_train = data.sample(frac = train_ratio)\n",
    "    data_test = data.drop(data_train.index)\n",
    "    return data_train, data_test\n",
    "\n",
    "# Diviser notre jeu de données en 2 : train et test\n",
    "data_train, data_test = split_data(data, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11797, 3), (7865, 3))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape, data_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans notre cas :\n",
    "+ entraînement (appelé *Train*) contenant 11797 observations ;\n",
    "+ validation (appelé *Validation*) contenant 5243 observations ;\n",
    "+ test (appelé *Test*), contenant 2622 observations, soit environ 22% de la taille du jeu d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>score_avis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14207</th>\n",
       "      <td>14207</td>\n",
       "      <td>This tank/blouse is flowy and i love the desig...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20479</th>\n",
       "      <td>20479</td>\n",
       "      <td>This is a really cute style of t-sihrt. i tota...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18930</th>\n",
       "      <td>18930</td>\n",
       "      <td>These are not only comfortable, but so cute. t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20736</th>\n",
       "      <td>20736</td>\n",
       "      <td>I love these pants. they are very flattering a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16451</th>\n",
       "      <td>16451</td>\n",
       "      <td>I bought this well made cute top today and lov...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                        Review Text  score_avis\n",
       "14207  14207  This tank/blouse is flowy and i love the desig...           1\n",
       "20479  20479  This is a really cute style of t-sihrt. i tota...           0\n",
       "18930  18930  These are not only comfortable, but so cute. t...           1\n",
       "20736  20736  I love these pants. they are very flattering a...           1\n",
       "16451  16451  I bought this well made cute top today and lov...           1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>score_avis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>I love tracy reese dresses, but this one is no...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>I ordered this in carbon for store pick up, an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>More and more i find myself reliant on the rev...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Bought the black xs to go under the larkspur m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                        Review Text  score_avis\n",
       "4    4  This shirt is very flattering to all due to th...           1\n",
       "5    5  I love tracy reese dresses, but this one is no...          -1\n",
       "7    7  I ordered this in carbon for store pick up, an...           0\n",
       "12  12  More and more i find myself reliant on the rev...           1\n",
       "13  13  Bought the black xs to go under the larkspur m...           1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution des classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est important de connaître la répartition des classes dans les données d'entraînement pour pouvoir procéder à notre classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_avis\n",
      " 1    6546\n",
      " 0    4024\n",
      "-1    1227\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "score_avis\n",
       " 1    0.554887\n",
       " 0    0.341104\n",
       "-1    0.104009\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyse de la colonne \"score_avis\" de notre jeu de données d'entrainement\n",
    "print(data_train[\"score_avis\"].value_counts())\n",
    "\n",
    "# Calcul des proportions de chaque classe dans notre jeu de données d'entrainement\n",
    "data_train[\"score_avis\"].value_counts()/len(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons observer que les classes de scores sont réparties de manière aléatoire dans notre jeu d'apprentissage. Nous pouvons noter plus de 50% d'avis très favorables, correspondant à la note de 5/5. Les avis négatifs sont en minorité dans notre jeu d'entraînement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploration du texte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour se faire une idée des textes auxquels nous avons affaire, nous allons les afficher pour savoir quels pré-traitements sont nécessaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['This tank/blouse is flowy and i love the design. it was immediately comfortable and seemed true to size. i wore it to a family event with a sweater, black leggings and boots. i\\'m 5\\'5,\" 36d and usually wear medium in retailer tops and this fit beautifully from the get go, just love it!',\n",
       "       'This is a really cute style of t-sihrt. i totally disagree with the reviewers who thought this was too short in the torso and/or overwhelming. i\\'m 5\\'8\" and about 145 pounds and this fits just fine. (i ordered a size small.) beautiful drape and (i thought) relatively slim cut. the only reason i\\'m not giving this 5 stars across the board is that the fabric is a little too thin (not sheer or see-through, but not as substantial as i would expect for the price.',\n",
       "       'These are not only comfortable, but so cute. they are something you don\\'t see on everyone else, and people always comment. i get so many compliments or inquiries every time i have them on. the materiel is lightweight and flowing. i love these casual, beautiful beach pants. i got a small, my usual size and they fit great. 5\\'3\\'\", 130 lb.s. i wear tee shirts, bathing tops, coobies, any kind of top looks swell. get them while you can. i got the peach and black color.',\n",
       "       \"I love these pants. they are very flattering and comfy, and look like real leather. they are also machine washable which is great. i've worn mine 5 times already.\",\n",
       "       'I bought this well made cute top today and love it. it can be day time casual or dressy for dinner. you will want to probably wear a cami underneath since its see through. its perfect for summer! im a 36d, 5\\'7\" 135 pounds, and usually wear a medium, but the small fit perfectly with room to spare. cuter in person.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Affichage des 5 premiers avis\n",
    "data_train[\"Review Text\"].values[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_examples</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>1227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_examples\n",
       "class              \n",
       " 1             6546\n",
       " 0             4024\n",
       "-1             1227"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "class_distribution = (pd.DataFrame.from_dict(Counter(data_train.score_avis.values),\n",
    "                                             orient='index')\n",
    "                                  .rename(columns={0: 'num_examples'}))\n",
    "class_distribution.index.name = 'class'\n",
    "class_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_examples</th>\n",
       "      <th>perc_examples</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6546</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4024</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>1227</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_examples  perc_examples\n",
       "class                             \n",
       " 1             6546           0.55\n",
       " 0             4024           0.34\n",
       "-1             1227           0.10"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class_distribution['perc_examples'] = np.around(class_distribution.num_examples /\n",
    "                                                np.sum(class_distribution.num_examples),\n",
    "                                                2)\n",
    "class_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Représentation des textes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sélection de descripteurs : prétraitements textuels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exemple sur un avis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Absolutely beautiful and well made. this pair of jeans is perfect, no flaws whatsoever. i usually wear size 27 but bought the 26 as it fits better. 27 is very slightly loose but i think it supposed to be like that for a boyfriend jeans. i prefer it nice and fitted, so 26 works better. i'm lucky to find them still available in the store while it's not online. i didn't hesitate to buy at full price, which i rarely did. i'm so in love with my new purchase. very happy!\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw = data_train['Review Text'].iloc[100]\n",
    "tw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour effectuer nos tâches de traitements de langage, nous allons transformer le 1er avis en utilisant spacy. En effet, spacy a plusieurs fonctionnalités : \n",
    "- permet de tokeniser directement notre texte\n",
    "- peut lemmatiser les mots\n",
    "- identifier et classer les entités nommées\n",
    "- analyser les dépendances syntaxiques entre les mots\n",
    "- représenter les mots sous forme de vecteurs (embedding)\n",
    "- etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\asus\\anaconda3\\lib\\site-packages (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (0.3.3)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (1.10.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (1.24.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n",
      "\n",
      "⠙ Loading compatibility table...\n",
      "⠹ Loading compatibility table...\n",
      "⠸ Loading compatibility table...\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded compatibility table\u001b[0m\n",
      "\u001b[1m\n",
      "================= Installed pipeline packages (spaCy v3.7.2) =================\u001b[0m\n",
      "\u001b[38;5;4mℹ spaCy installation:\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\spacy\u001b[0m\n",
      "\n",
      "NAME              SPACY            VERSION                            \n",
      "en_core_web_sm    >=3.7.2,<3.8.0   \u001b[38;5;2m3.7.1\u001b[0m   \u001b[38;5;2m✔\u001b[0m\n",
      "fr_core_news_sm   >=3.7.0,<3.8.0   \u001b[38;5;2m3.7.0\u001b[0m   \u001b[38;5;2m✔\u001b[0m\n",
      "\n",
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/12.8 MB 320.0 kB/s eta 0:00:40\n",
      "     --------------------------------------- 0.0/12.8 MB 487.6 kB/s eta 0:00:27\n",
      "      --------------------------------------- 0.2/12.8 MB 1.2 MB/s eta 0:00:11\n",
      "     -- ------------------------------------- 0.8/12.8 MB 4.4 MB/s eta 0:00:03\n",
      "     -------- ------------------------------- 2.7/12.8 MB 11.5 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 6.2/12.8 MB 21.9 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.3/12.8 MB 28.3 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 11.8/12.8 MB 59.8 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.8/12.8 MB 65.6 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.8/12.8 MB 50.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.7.1) (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.3)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.10.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.24.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# Pour la langue anglaise\n",
    "!pip install -U spacy\n",
    "! python -m spacy validate\n",
    "\n",
    "import spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "This dress in a lovely platinum is feminine and fits perfectly, easy to wear and comfy, too! highly recommend!"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformation du premier avis en objet spacy\n",
    "avis_nlp = nlp(avis) \n",
    "avis_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(avis_nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a bien un objet de type spacy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On affiche chaque token de notre objet spacy :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This\n",
      "dress\n",
      "in\n",
      "a\n",
      "lovely\n",
      "platinum\n",
      "is\n",
      "feminine\n",
      "and\n",
      "fits\n",
      "perfectly\n",
      ",\n",
      "easy\n",
      "to\n",
      "wear\n",
      "and\n",
      "comfy\n",
      ",\n",
      "too\n",
      "!\n",
      "highly\n",
      "recommend\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "for token in avis_nlp:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, nous allons pouvoir afficher les lemmes de chaque token. Grâce à cette étape, nous allons pouvoir simplifier les mots pour faciliter notre analyse textuelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this\n",
      "dress\n",
      "in\n",
      "a\n",
      "lovely\n",
      "platinum\n",
      "be\n",
      "feminine\n",
      "and\n",
      "fit\n",
      "perfectly\n",
      ",\n",
      "easy\n",
      "to\n",
      "wear\n",
      "and\n",
      "comfy\n",
      ",\n",
      "too\n",
      "!\n",
      "highly\n",
      "recommend\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "# Lemmatisation\n",
    "for token in avis_nlp:\n",
    "    print(token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Généralisation de la lemmatisation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour lemmatiser notre texte, nous allons définir une fonction. Cette étape est indispensable pour récupérer les lemmes des mots de notre texte d'origine. Nous allons simplifier notre texte grâce à cette fonction.\n",
    "\n",
    "Cette fonction va nous permettre de généraliser par la suite nos manipulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatise_text(text):\n",
    "    text = nlp(text) # on transforme le texte en objet spacy\n",
    "    lemmas = [token.lemma_ for token in text] # on récupère les lemmes\n",
    "    return ' '.join(lemmas) # on retourne les lemmes sous forme de texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avis initial :  I had such high hopes for this dress and really wanted it to work for me. i initially ordered the petite small (my usual size) but i found this to be outrageously small. so small in fact that i could not zip it up! i reordered it in petite medium, which was just ok. overall, the top half was comfortable and fit nicely, but the bottom half had a very tight under layer and several somewhat cheap (net) over layers. imo, a major design flaw was the net over layer sewn directly into the zipper - it c\n",
      "Avis lemmatisé :  I have such high hope for this dress and really want it to work for I . I initially order the petite small ( my usual size ) but I find this to be outrageously small . so small in fact that I could not zip it up ! I reorder it in petite medium , which be just ok . overall , the top half be comfortable and fit nicely , but the bottom half have a very tight under layer and several somewhat cheap ( net ) over layer . imo , a major design flaw be the net over layer sew directly into the zipper - it c\n",
      "Avis initial :  I love, love, love this jumpsuit. it's fun, flirty, and fabulous! every time i wear it, i get nothing but great compliments!\n",
      "Avis lemmatisé :  I love , love , love this jumpsuit . it be fun , flirty , and fabulous ! every time I wear it , I get nothing but great compliment !\n",
      "Avis initial :  This shirt is very flattering to all due to the adjustable front tie. it is the perfect length to wear with leggings and it is sleeveless so it pairs well with any cardigan. love this shirt!!!\n",
      "Avis lemmatisé :  this shirt be very flattering to all due to the adjustable front tie . it be the perfect length to wear with legging and it be sleeveless so it pair well with any cardigan . love this shirt ! ! !\n"
     ]
    }
   ],
   "source": [
    "# On teste sur 3 avis \n",
    "for avis in liste_avis[:3]:\n",
    "    print(\"Avis initial : \", avis) # On affiche l'avis initial\n",
    "    print(\"Avis lemmatisé : \", lemmatise_text(avis)) # On applique la fonction à notre avis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons ensuite ajouter une colonne avec la fonction de **lemmatisation** appliquée à nos avis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['lemmas'] = data_train['Review Text'].apply(lemmatise_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>score_avis</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14207</th>\n",
       "      <td>14207</td>\n",
       "      <td>This tank/blouse is flowy and i love the desig...</td>\n",
       "      <td>1</td>\n",
       "      <td>this tank / blouse be flowy and I love the des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20479</th>\n",
       "      <td>20479</td>\n",
       "      <td>This is a really cute style of t-sihrt. i tota...</td>\n",
       "      <td>0</td>\n",
       "      <td>this be a really cute style of t - sihrt . I t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18930</th>\n",
       "      <td>18930</td>\n",
       "      <td>These are not only comfortable, but so cute. t...</td>\n",
       "      <td>1</td>\n",
       "      <td>these be not only comfortable , but so cute . ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20736</th>\n",
       "      <td>20736</td>\n",
       "      <td>I love these pants. they are very flattering a...</td>\n",
       "      <td>1</td>\n",
       "      <td>I love these pant . they be very flattering an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16451</th>\n",
       "      <td>16451</td>\n",
       "      <td>I bought this well made cute top today and lov...</td>\n",
       "      <td>1</td>\n",
       "      <td>I buy this well make cute top today and love i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                        Review Text  score_avis  \\\n",
       "14207  14207  This tank/blouse is flowy and i love the desig...           1   \n",
       "20479  20479  This is a really cute style of t-sihrt. i tota...           0   \n",
       "18930  18930  These are not only comfortable, but so cute. t...           1   \n",
       "20736  20736  I love these pants. they are very flattering a...           1   \n",
       "16451  16451  I bought this well made cute top today and lov...           1   \n",
       "\n",
       "                                                  lemmas  \n",
       "14207  this tank / blouse be flowy and I love the des...  \n",
       "20479  this be a really cute style of t - sihrt . I t...  \n",
       "18930  these be not only comfortable , but so cute . ...  \n",
       "20736  I love these pant . they be very flattering an...  \n",
       "16451  I buy this well make cute top today and love i...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On effectue la même manipulation sur l'ensemble de test ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['lemmas'] = data_test['Review Text'].apply(lemmatise_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7865, 4)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde\n",
    "data_train.to_pickle('train.pkl')\n",
    "data_test.to_pickle('test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Racines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour réduire les mots à leur forme de base, nous allons utiliser SnowballStemmer sur notre texte. Pour cela, nous allons créer une fonction et l'appliquer à nos avis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_text(text):\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    tokenizer = RegexpTokenizer('\\w+')\n",
    "    stems = [stemmer.stem(token) for token in tokenizer.tokenize(text)]\n",
    "    return ' '.join(stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this shirt is veri flatter to all due to the adjust front tie it is the perfect length to wear with leg and it is sleeveless so it pair well with ani cardigan love this shirt'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_text(avis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On applique la fonction à notre dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['stems'] = data_train['Review Text'].apply(stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>score_avis</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>stems</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14207</th>\n",
       "      <td>14207</td>\n",
       "      <td>This tank/blouse is flowy and i love the desig...</td>\n",
       "      <td>1</td>\n",
       "      <td>this tank / blouse be flowy and I love the des...</td>\n",
       "      <td>this tank blous is flowi and i love the design...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20479</th>\n",
       "      <td>20479</td>\n",
       "      <td>This is a really cute style of t-sihrt. i tota...</td>\n",
       "      <td>0</td>\n",
       "      <td>this be a really cute style of t - sihrt . I t...</td>\n",
       "      <td>this is a realli cute style of t sihrt i total...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18930</th>\n",
       "      <td>18930</td>\n",
       "      <td>These are not only comfortable, but so cute. t...</td>\n",
       "      <td>1</td>\n",
       "      <td>these be not only comfortable , but so cute . ...</td>\n",
       "      <td>these are not onli comfort but so cute they ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20736</th>\n",
       "      <td>20736</td>\n",
       "      <td>I love these pants. they are very flattering a...</td>\n",
       "      <td>1</td>\n",
       "      <td>I love these pant . they be very flattering an...</td>\n",
       "      <td>i love these pant they are veri flatter and co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16451</th>\n",
       "      <td>16451</td>\n",
       "      <td>I bought this well made cute top today and lov...</td>\n",
       "      <td>1</td>\n",
       "      <td>I buy this well make cute top today and love i...</td>\n",
       "      <td>i bought this well made cute top today and lov...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                        Review Text  score_avis  \\\n",
       "14207  14207  This tank/blouse is flowy and i love the desig...           1   \n",
       "20479  20479  This is a really cute style of t-sihrt. i tota...           0   \n",
       "18930  18930  These are not only comfortable, but so cute. t...           1   \n",
       "20736  20736  I love these pants. they are very flattering a...           1   \n",
       "16451  16451  I bought this well made cute top today and lov...           1   \n",
       "\n",
       "                                                  lemmas  \\\n",
       "14207  this tank / blouse be flowy and I love the des...   \n",
       "20479  this be a really cute style of t - sihrt . I t...   \n",
       "18930  these be not only comfortable , but so cute . ...   \n",
       "20736  I love these pant . they be very flattering an...   \n",
       "16451  I buy this well make cute top today and love i...   \n",
       "\n",
       "                                                   stems  \n",
       "14207  this tank blous is flowi and i love the design...  \n",
       "20479  this is a realli cute style of t sihrt i total...  \n",
       "18930  these are not onli comfort but so cute they ar...  \n",
       "20736  i love these pant they are veri flatter and co...  \n",
       "16451  i bought this well made cute top today and lov...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On fait de même sur l'ensemble de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['stems'] = data_test['Review Text'].apply(stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7865, 5)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde\n",
    "data_train.to_pickle('train.pkl')\n",
    "data_test.to_pickle('test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Étiquettes morphosyntaxiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis, nous allons analyser notre texte et renvoyer chaque mot remplacé par sa catégorie grammaticale pour continuer l'étude des avis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_words_with_pos_tag(text):\n",
    "    text = nlp(text)\n",
    "    return ' '.join([token.pos_ for token in text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On teste la fonction sur un avis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DET NOUN AUX ADV ADJ ADP PRON ADP ADP DET ADJ ADJ NOUN PUNCT PRON AUX DET ADJ NOUN PART VERB ADP NOUN CCONJ PRON AUX ADJ SCONJ PRON VERB ADV ADP DET NOUN PUNCT VERB DET NOUN PUNCT PUNCT PUNCT'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_words_with_pos_tag(avis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On applique la fonction à notre ensemble d'entrainement et on ajoute une colonne à notre dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['pos'] = data_train['Review Text'].apply(replace_words_with_pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>score_avis</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>stems</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14207</th>\n",
       "      <td>14207</td>\n",
       "      <td>This tank/blouse is flowy and i love the desig...</td>\n",
       "      <td>1</td>\n",
       "      <td>this tank / blouse be flowy and I love the des...</td>\n",
       "      <td>this tank blous is flowi and i love the design...</td>\n",
       "      <td>DET NOUN SYM NOUN AUX ADJ CCONJ PRON VERB DET ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20479</th>\n",
       "      <td>20479</td>\n",
       "      <td>This is a really cute style of t-sihrt. i tota...</td>\n",
       "      <td>0</td>\n",
       "      <td>this be a really cute style of t - sihrt . I t...</td>\n",
       "      <td>this is a realli cute style of t sihrt i total...</td>\n",
       "      <td>PRON AUX DET ADV ADJ NOUN ADP PROPN PUNCT NOUN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18930</th>\n",
       "      <td>18930</td>\n",
       "      <td>These are not only comfortable, but so cute. t...</td>\n",
       "      <td>1</td>\n",
       "      <td>these be not only comfortable , but so cute . ...</td>\n",
       "      <td>these are not onli comfort but so cute they ar...</td>\n",
       "      <td>PRON AUX PART ADV ADJ PUNCT CCONJ ADV ADJ PUNC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20736</th>\n",
       "      <td>20736</td>\n",
       "      <td>I love these pants. they are very flattering a...</td>\n",
       "      <td>1</td>\n",
       "      <td>I love these pant . they be very flattering an...</td>\n",
       "      <td>i love these pant they are veri flatter and co...</td>\n",
       "      <td>PRON VERB DET NOUN PUNCT PRON AUX ADV ADJ CCON...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16451</th>\n",
       "      <td>16451</td>\n",
       "      <td>I bought this well made cute top today and lov...</td>\n",
       "      <td>1</td>\n",
       "      <td>I buy this well make cute top today and love i...</td>\n",
       "      <td>i bought this well made cute top today and lov...</td>\n",
       "      <td>PRON VERB PRON ADV VERB ADJ NOUN NOUN CCONJ VE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                        Review Text  score_avis  \\\n",
       "14207  14207  This tank/blouse is flowy and i love the desig...           1   \n",
       "20479  20479  This is a really cute style of t-sihrt. i tota...           0   \n",
       "18930  18930  These are not only comfortable, but so cute. t...           1   \n",
       "20736  20736  I love these pants. they are very flattering a...           1   \n",
       "16451  16451  I bought this well made cute top today and lov...           1   \n",
       "\n",
       "                                                  lemmas  \\\n",
       "14207  this tank / blouse be flowy and I love the des...   \n",
       "20479  this be a really cute style of t - sihrt . I t...   \n",
       "18930  these be not only comfortable , but so cute . ...   \n",
       "20736  I love these pant . they be very flattering an...   \n",
       "16451  I buy this well make cute top today and love i...   \n",
       "\n",
       "                                                   stems  \\\n",
       "14207  this tank blous is flowi and i love the design...   \n",
       "20479  this is a realli cute style of t sihrt i total...   \n",
       "18930  these are not onli comfort but so cute they ar...   \n",
       "20736  i love these pant they are veri flatter and co...   \n",
       "16451  i bought this well made cute top today and lov...   \n",
       "\n",
       "                                                     pos  \n",
       "14207  DET NOUN SYM NOUN AUX ADJ CCONJ PRON VERB DET ...  \n",
       "20479  PRON AUX DET ADV ADJ NOUN ADP PROPN PUNCT NOUN...  \n",
       "18930  PRON AUX PART ADV ADJ PUNCT CCONJ ADV ADJ PUNC...  \n",
       "20736  PRON VERB DET NOUN PUNCT PRON AUX ADV ADJ CCON...  \n",
       "16451  PRON VERB PRON ADV VERB ADJ NOUN NOUN CCONJ VE...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On effectue la même manipulation sur notre ensemble de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['pos'] = data_test['Review Text'].apply(replace_words_with_pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7865, 6)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde\n",
    "data_train.to_pickle('train.pkl')\n",
    "data_test.to_pickle('test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Classe d'appartenance des entités nommées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour pouvoir effectuer la reconnaissances d'entités nommées sur nos avis, nous allons retourner une version de notre avis ou chaque entité nommée est remplacée par son type d'entité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner(text):\n",
    "\n",
    "    text = nlp(text) # on transforme le texte en objet spacy\n",
    "    \n",
    "    new_text = [] # on crée une liste vide\n",
    "\n",
    "    for token in text: # pour chaque token dans l'avis\n",
    "\n",
    "        # print(token.text, token.ent_iob_, token.ent_type_)\n",
    "        \n",
    "        if token.ent_iob_ == \"O\": # si l'entité ne fait pas partie d'une entité nommée\n",
    "            new_text.append(token.text) # on ajoute le texte du token à la liste\n",
    "        elif token.ent_iob_ == \"B\": # si l'entité fait partie d'une entité nommée\n",
    "            new_text.append(token.ent_type_) # on ajoute le type de l'entité à la liste\n",
    "\n",
    "        # Si l'entité comprend plusieurs mot on ne répète pas l'étiquette\n",
    "        else:\n",
    "            continue\n",
    "    return ' '.join(new_text) # on retourne les étiquettes sous forme de texte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On applique la fonction sur trois avis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avis initiaux :  This shirt is very flattering to all due to the adjustable front tie. it is the perfect length to wear with leggings and it is sleeveless so it pairs well with any cardigan. love this shirt!!!\n",
      "Avec les entités nommées :  This shirt is very flattering to all due to the adjustable front tie . it is the perfect length to wear with leggings and it is sleeveless so it pairs well with any cardigan . love this shirt ! ! !\n"
     ]
    }
   ],
   "source": [
    "# On applique la fonction sur trois avis.\n",
    "for avis in liste_avis[:3]:\n",
    "    print(\"Avis initial : \", avis) # On affiche l'avis initial\n",
    "    print(\"Avis avec entités nommées : \", ner(avis)) # On applique la fonction à notre avis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, l'utilisation d'entitées nommées ne nous apporte pas d'information puisqu'il s'agit d'avis. On rapelle qu'un avis ne contient pas forcément d'avis, de lieux, de dates etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Calcul des valeurs des descripteurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour procéder aux calculs, nous allons séparer notre jeu de données d'entraînement pour avoir un jeu de données de validation. Les données test nou servirons pour l'évaluation finale des modèles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(data_train['Review Text'],\n",
    "                                                      data_train['score_avis'],\n",
    "                                                      train_size=0.75,\n",
    "                                                      random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8847,), (2950,))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a donc 8 847 lignes dans notre jeu d'entrainement et 2 950 dans celui de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13907    0\n",
       "16335    1\n",
       "20432    0\n",
       "2500     0\n",
       "1540     0\n",
       "        ..\n",
       "12151    0\n",
       "14584    1\n",
       "23297    1\n",
       "2481     1\n",
       "10811    1\n",
       "Name: score_avis, Length: 8847, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons observer que les sorties à prédire correspondent aux trois étiquettes que nous avons défini plus haut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour évaluer notre modèle, nous initialisons les ensembles de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On récupère les avis et les labels du jeu de données de test\n",
    "X_test, y_test = data_test['Review Text'], data_test['score_avis'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binaire : présence/absence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "bin_count = CountVectorizer(binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(binary=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(binary=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer(binary=True)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_count.fit(X_train)\n",
    "bin_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8847x9562 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 387246 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectorized_bin = bin_count.transform(X_train)\n",
    "X_train_vectorized_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_vectorized_bin = bin_count.transform(X_valid)\n",
    "X_test_vectorized_bin = bin_count.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2950x9562 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 128942 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid_vectorized_bin # MEME NOMBRE DE COLONNES QUE X_train_vectorized_bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Numérique discret : décomptes d'occurrence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons calculer les fréquences d'occurence des termes dans nos avis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_count = CountVectorizer().fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons examiner le vocabulaire de nos avis : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '00p', '02', '03', '0in', '0p', '0petite', '0r', '0verall',\n",
       "       '0xs', '10', '100', '1000', '100lbs', '102', '102lbs', '103',\n",
       "       '103lb', '103lbs', '104', '104lbs', '105', '105lb', '105lbs',\n",
       "       '106', '106lbs', '107', '107lb', '107lbs', '107pound', '108',\n",
       "       '108lbs', '109', '109lbs', '10lbs', '10p', '10x', '11', '110',\n",
       "       '110lbs', '111lbs', '112', '112lb', '112lbs', '112llbs', '113',\n",
       "       '113lbs', '114', '114lbs', '115'], dtype=object)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_count.get_feature_names_out()[:50] # 50 premiers mots (\"types\" du vocabulaire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['yes', 'yesterday', 'yet', 'yey', 'yfit', 'yield', 'yielded',\n",
       "       'yikes', 'yo', 'yoga', 'yogini', 'yoke', 'york', 'you', 'young',\n",
       "       'younger', 'your', 'youre', 'yourself', 'yourselves', 'youthful',\n",
       "       'yr', 'yrs', 'yuck', 'yucky', 'yummiest', 'yummy', 'yup', 'zag',\n",
       "       'zermatt', 'zero', 'zeros', 'zig', 'zigzag', 'zigzagging',\n",
       "       'zillion', 'zip', 'zipepr', 'ziploc', 'zipped', 'zipper',\n",
       "       'zippered', 'zippers', 'zippie', 'zipping', 'zips', 'zombie',\n",
       "       'zone', 'zoom', 'zuma'], dtype=object)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_count.get_feature_names_out()[-50:] # 50 derniers mots (\"types\" du vocabulaire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taille de notre vocabulaire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9562"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect_count.get_feature_names_out()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Création matrice document-termes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons créer la matrice document-termes avec le même vectoriseur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8847x9562 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 387246 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectorized_count = vect_count.transform(X_train)\n",
    "X_train_vectorized_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_vectorized_count = vect_count.transform(X_valid)\n",
    "X_test_vectorized_count = vect_count.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A présent, nous allons prendre en compte les bi-grammes dans notre vocabulaire. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_count_bigrams = CountVectorizer(min_df=5, ngram_range=(1,2)).fit(X_train)\n",
    "X_train_vectorized_count_bigrams = vect_count_bigrams.transform(X_train)\n",
    "X_valid_vectorized_count_bigrams = vect_count_bigrams.transform(X_valid)\n",
    "X_test_vectorized_count_bigrams = vect_count_bigrams.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17352"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect_count_bigrams.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons presque 2 fois plus de vocabulaire avec inclusion des bigrammes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRI-GRAMMES \n",
    "# filtres sur des catégories (adj+nom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Numérique continu : TF-IDF (ou autres pondérations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons limiter le vocabulaire à des termes qui apparaissent au moins 5 fois dans le document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_tfidf = TfidfVectorizer(min_df=5).fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9562, 3231)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect_count.get_feature_names_out()), len(vect_tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La réduction de la taille du vocadulaire est importante et est due au paramètre min_df=5 : on a quasiment 3 fois moins de termes !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons vectoriser les jeux de données. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorisation des corpus d'entrainement, de validation et de test\n",
    "X_train_vectorized_tfidf = vect_tfidf.transform(X_train)\n",
    "X_valid_vectorized_tfidf = vect_tfidf.transform(X_valid)\n",
    "X_test_vectorized_tfidf = vect_tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification des textes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons réaliser une classification en utilisant plusieurs modèles afin de comparer les performances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèles de référence faibles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choix aléatoire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons d'abord choisir un modèle où toutes les classes ont la même probabilité d'être choisies ou bien le prédicteur respecte la disctribution des classes dans les données d'entrainement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prédiction proportionnelle à la distribution des classes dans les données d'entraînement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_prop_class = DummyClassifier(strategy='stratified').fit(X_train_vectorized_tfidf,\n",
    "                                                               y_train)\n",
    "predictions_valid = random_prop_class.predict(X_valid_vectorized_tfidf)\n",
    "conf_mat = confusion_matrix(y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 37 105 170]\n",
      " [107 324 588]\n",
      " [173 539 907]]\n"
     ]
    }
   ],
   "source": [
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prédiction uniforme : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  0, ...,  1,  0, -1], dtype=int64)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_uniform = DummyClassifier(strategy='uniform').fit(X_train_vectorized_tfidf,\n",
    "                                                         y_train)\n",
    "predictions_valid = random_uniform.predict(X_valid_vectorized_tfidf)\n",
    "predictions_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100 109 103]\n",
      " [358 336 325]\n",
      " [547 563 509]]\n"
     ]
    }
   ],
   "source": [
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32033898305084746"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.10      0.32      0.15       312\n",
      "           0       0.33      0.33      0.33      1019\n",
      "           1       0.54      0.31      0.40      1619\n",
      "\n",
      "    accuracy                           0.32      2950\n",
      "   macro avg       0.33      0.32      0.29      2950\n",
      "weighted avg       0.42      0.32      0.35      2950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, predictions_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prédiction constante de la classe majoritaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons d'abord identifier la répartition des classes dans les données d'entrainement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_examples</th>\n",
       "      <th>perc_examples</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6546</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4024</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>1227</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_examples  perc_examples\n",
       "class                             \n",
       " 1             6546           0.55\n",
       " 0             4024           0.34\n",
       "-1             1227           0.10"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maj = DummyClassifier(strategy='most_frequent').fit(X_train_vectorized_tfidf, y_train)\n",
    "predictions_valid = maj.predict(X_valid_vectorized_tfidf)\n",
    "predictions_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "maj_class = (class_distribution.index[class_distribution.perc_examples ==\n",
    "                                      np.amax(class_distribution.perc_examples)][0])\n",
    "maj_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(predictions_valid == maj_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5488135593220339"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maj.score(X_valid_vectorized_tfidf, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       312\n",
      "           0       0.00      0.00      0.00      1019\n",
      "           1       0.55      1.00      0.71      1619\n",
      "\n",
      "    accuracy                           0.55      2950\n",
      "   macro avg       0.18      0.33      0.24      2950\n",
      "weighted avg       0.30      0.55      0.39      2950\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, predictions_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifieur naïf bayésien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nb = MultinomialNB().fit(X_train_vectorized_tfidf, y_train)\n",
    "predictions_valid = model_nb.predict(X_valid_vectorized_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6749152542372882"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.80      0.01      0.03       312\n",
      "           0       0.58      0.46      0.51      1019\n",
      "           1       0.71      0.94      0.81      1619\n",
      "\n",
      "    accuracy                           0.67      2950\n",
      "   macro avg       0.70      0.47      0.45      2950\n",
      "weighted avg       0.67      0.67      0.62      2950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, predictions_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model_lr = LogisticRegression(multi_class='multinomial', solver='lbfgs',\n",
    "                              max_iter=200).fit(X_train_vectorized_count, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_valid = model_lr.predict(X_valid_vectorized_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6850847457627118"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.48      0.41      0.44       312\n",
      "           0       0.57      0.56      0.57      1019\n",
      "           1       0.78      0.82      0.80      1619\n",
      "\n",
      "    accuracy                           0.69      2950\n",
      "   macro avg       0.61      0.59      0.60      2950\n",
      "weighted avg       0.68      0.69      0.68      2950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, predictions_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_n_strongly_associated_features(vectoriser, model, n):\n",
    "    feature_names = np.array(vectoriser.get_feature_names_out())\n",
    "\n",
    "    for i in range(3):\n",
    "        class_name = model.classes_[i]\n",
    "        print(\"CLASSE {}\".format(class_name))\n",
    "        idx_coefs_sorted = model.coef_[i].argsort() # ordre croissant\n",
    "        print(\"Les dix variables ayant l'association négative la plus forte \" + \n",
    "              \"avec la classe {} :\\n{}\\n\".format(class_name,\n",
    "                                                 feature_names[idx_coefs_sorted[:n]]))\n",
    "        idx_coefs_sorted = idx_coefs_sorted[::-1] # ordre décroissant\n",
    "        print(\"Les dix variables ayant l'association positive la plus forte \" +\n",
    "              \"avec la classe {} :\\n{}\\n\"\n",
    "              .format(class_name,\n",
    "                      feature_names[idx_coefs_sorted[:n]]))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examinons les variables (termes) ayant l'association la plus forte avec chaque classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSE -1\n",
      "Les dix variables ayant l'association négative la plus forte avec la classe -1 :\n",
      "['amazing' 'compliments' 'wait' 'meant' 'worried' 'stunning' 'threads'\n",
      " 'versatile' 'fan' 'avoid']\n",
      "\n",
      "Les dix variables ayant l'association positive la plus forte avec la classe -1 :\n",
      "['horrible' 'poor' 'cheap' 'bulky' 'anticipated' 'maternity'\n",
      " 'disappointing' 'awkward' 'huge' 'covered']\n",
      "\n",
      "\n",
      "CLASSE 0\n",
      "Les dix variables ayant l'association négative la plus forte avec la classe 0 :\n",
      "['waistline' 'wound' 'allows' 'virtually' 'friday' 'preference' 'hi'\n",
      " 'customer' 'holding' 'waiting']\n",
      "\n",
      "Les dix variables ayant l'association positive la plus forte avec la classe 0 :\n",
      "['replacement' 'prior' 'patterned' 'hadn' 'ddd' 'continue' 'pulls' 'bc'\n",
      " 'scrunch' 'fair']\n",
      "\n",
      "\n",
      "CLASSE 1\n",
      "Les dix variables ayant l'association négative la plus forte avec la classe 1 :\n",
      "['returning' 'disappointing' 'odd' 'huge' 'waste' 'disappointed' 'poor'\n",
      " 'idea' 'apart' 'unfortunately']\n",
      "\n",
      "Les dix variables ayant l'association positive la plus forte avec la classe 1 :\n",
      "['wound' 'hesitant' 'highly' 'formal' 'friday' 'stunning' 'hi' 'amazing'\n",
      " 'florida' 'preference']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_n_strongly_associated_features(vect_count, model_lr, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMENTAIRE A METTRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model_lr = LogisticRegression(multi_class='multinomial',\n",
    "                              solver='lbfgs').fit(X_train_vectorized_tfidf, y_train)\n",
    "predictions_valid = model_lr.predict(X_valid_vectorized_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7223728813559323"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.64      0.28      0.39       312\n",
      "           0       0.61      0.61      0.61      1019\n",
      "           1       0.79      0.88      0.83      1619\n",
      "\n",
      "    accuracy                           0.72      2950\n",
      "   macro avg       0.68      0.59      0.61      2950\n",
      "weighted avg       0.71      0.72      0.71      2950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, predictions_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF le moins élevé : ['shut' 'pros' 'secondly' 'wondering' 'fo' 'wi' 'trigger' 'lik' 'framed'\n",
      " 'monitor']\n",
      "TF-IDF le plus élevé : ['birds' 'structure' 'amp' 'comfort' 'simple' 'wonderful' 'exciting' 'she'\n",
      " 'royal' 'awesome']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vect_tfidf.get_feature_names_out())\n",
    "idx_tfidf_sorted = X_train_vectorized_tfidf.max(0).toarray()[0].argsort()\n",
    "print(\"TF-IDF le moins élevé : {}\".format(feature_names[idx_tfidf_sorted[:10]]))\n",
    "print(\"TF-IDF le plus élevé : {}\".format(feature_names[idx_tfidf_sorted[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous faisons avec les mêmes paramètres mais avec le vectoriseur à unigrammes et bigrammes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LogisticRegression(multi_class='multinomial', solver='lbfgs',max_iter=500).fit(X_train_vectorized_count_bigrams, y_train)\n",
    "predictions_valid = model_lr.predict(X_valid_vectorized_count_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6983050847457627"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.52      0.39      0.44       312\n",
      "           0       0.58      0.58      0.58      1019\n",
      "           1       0.79      0.84      0.81      1619\n",
      "\n",
      "    accuracy                           0.70      2950\n",
      "   macro avg       0.63      0.60      0.61      2950\n",
      "weighted avg       0.69      0.70      0.69      2950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, predictions_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSE -1\n",
      "Les dix variables ayant l'association négative la plus forte avec la classe -1 :\n",
      "['soft' 'amazing' 'compliments' 'love' 'think' 'little' 'beautiful'\n",
      " 'great' 'comfortable' 'be too']\n",
      "\n",
      "Les dix variables ayant l'association positive la plus forte avec la classe -1 :\n",
      "['cheap' 'unflattering' 'huge' 'frumpy' 'to love' 'were' 'going back'\n",
      " 'poor' 'bulky' 'weird']\n",
      "\n",
      "\n",
      "CLASSE 0\n",
      "Les dix variables ayant l'association négative la plus forte avec la classe 0 :\n",
      "['spring summer' 'but this' 'is lightweight' 'much fabric' 'sweater the'\n",
      " 'and didn' 'ever' 'elastic waist' 'bought size' 'more than']\n",
      "\n",
      "Les dix variables ayant l'association positive la plus forte avec la classe 0 :\n",
      "['top for' 'issue' 'not flattering' 'good for' 'is cute' 'returning it'\n",
      " 'this fit' 'design but' 'easily' 'is too']\n",
      "\n",
      "\n",
      "CLASSE 1\n",
      "Les dix variables ayant l'association négative la plus forte avec la classe 1 :\n",
      "['not flattering' 'returning' 'to love' 'disappointed' 'huge' 'were'\n",
      " 'is too' 'unfortunately' 'going back' 'scratchy']\n",
      "\n",
      "Les dix variables ayant l'association positive la plus forte avec la classe 1 :\n",
      "['perfect' 'beautifully' 'highly' 'the petite' 'more colors' 'soft'\n",
      " 'stunning' 'perfectly' 'amazing' 'fabric the']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_n_strongly_associated_features(vect_count_bigrams, model_lr, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svm = SVC(kernel='linear', C=0.1).fit(X_train_vectorized_count_bigrams, y_train)\n",
    "predictions_valid = model_svm.predict(X_valid_vectorized_count_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6874576271186441"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.46      0.44      0.45       312\n",
      "           0       0.57      0.55      0.56      1019\n",
      "           1       0.79      0.82      0.81      1619\n",
      "\n",
      "    accuracy                           0.69      2950\n",
      "   macro avg       0.61      0.60      0.61      2950\n",
      "weighted avg       0.68      0.69      0.68      2950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, predictions_valid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
